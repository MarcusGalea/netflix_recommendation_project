{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mmh3\n",
    "from src.structures import User, Movie\n",
    "from src.data_methods import read_movies,read_viewers\n",
    "import kagglehub\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "#please ikke offentliggør min api key. \n",
    "os.environ['KAGGLE_USERNAME'] = \"marcusgaleajacobsen\"\n",
    "os.environ['KAGGLE_KEY'] = \"32a3003f52c97053841ea46c492128dc\"\n",
    "datapath = kagglehub.dataset_download(\"netflix-inc/netflix-prize-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lines = 10000 #number of reviews to read\n",
    "datafiles = [\"combined_data_1.txt\"]#, \"combined_data_2.txt\", \"combined_data_3.txt\", \"combined_data_4.txt\"]\n",
    "with_tqdm = False #set to True to see progress bar (reduce speed)\n",
    "\n",
    "movies = read_movies(datapath)\n",
    "users = read_viewers(datapath, movies, datafiles = datafiles, with_tqdm= with_tqdm, n_lines=n_lines) #read only 100000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Signature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_minhashes(\n",
    "                    object: Movie | User, #movie or user to compute minhashes for\n",
    "                    n_hash = 100 #number of hashes\n",
    "                    ):\n",
    "    \n",
    "    bag = object.bag_ratings() #bag of ratings\n",
    "    hashes = np.array([[mmh3.hash(id, seed) for id in bag] for seed in range(n_hash)]) #hashes for each seed\n",
    "    minhashes = np.min(hashes, axis = 1) #minhashes for each seed\n",
    "    return minhashes\n",
    "\n",
    "def compute_signatures(\n",
    "                    objets: dict[str, Movie | User], #objects to compute signatures for\n",
    "                    n_hash = 100, #number of hashes\n",
    "                    with_tqdm = True #whether to show progress bar\n",
    "                    ):\n",
    "    iterator = tqdm(objets.items()) if with_tqdm else objets.items() #iterator\n",
    "    signatures = {id: compute_minhashes(obj, n_hash) for id, obj in iterator}\n",
    "    return signatures\n",
    "\n",
    "def bucket_hash(signatures, n_buckets = 100):\n",
    "    bucket = 0\n",
    "    for signature in signatures:\n",
    "        bucket = bucket ^ hash(signature) #xor of all signatures\n",
    "    return bucket % n_buckets #modulo n_buckets\n",
    "\n",
    "cartesian_product_exclude_same = lambda A,B : set((a,b) for a in A for b in B if (a != b and b > a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1810453357, -1570063170,  -184002522,  -126235597,  -172315920,\n",
       "        -346150140, -2131240906,  -793765815, -1571785578,  -977649233,\n",
       "        -535678046, -1457417976, -1562019656,   101162235, -1560298715,\n",
       "        -956861631,   168904549,   790285535, -2070529337,   625771924,\n",
       "        -249096934,   166839407, -1447133418, -1508133614,  -721831573,\n",
       "       -1056278211, -2114645946,  -381543989,     2653644,  -243094001,\n",
       "       -1200734897, -1428275679,  1687665648,  -677418915, -1473849242,\n",
       "        -248996816,  -893062816,  -576892624,  1653519337, -1799033939,\n",
       "       -1549378093, -1625405734, -1868994069, -1367157416,  1017076005,\n",
       "       -1384113491,  -310537956, -1527923987, -1384278664,   427621935,\n",
       "         369715913, -1778312296,   436922359,  -868451072,  -383727986,\n",
       "        -532758649, -2127377514,  -701845473,   559389694, -1995129985,\n",
       "         517183813,  1120606309,  -552741755,  -943591880, -1871239471,\n",
       "       -1987538483,  -818748851, -1542113122, -1668779179,   290657871,\n",
       "        -959982167, -2045232877, -1003898498,  -203119162,   713384309,\n",
       "       -1380004602, -1589545483,  -847925960,  1712351703, -1781344661,\n",
       "         917833904,  -697075599,  1477803771, -1448407665,  1896077532,\n",
       "        -203164242, -1477897465,   786831709,  -925067206,  -736368680,\n",
       "       -1171548884,  -811098947, -1112867387, -2029454380,  -610357792,\n",
       "        -838302847,   -46772570, -1838324511, -1400954927, -2032692195])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hash = 100    \n",
    "user = users[\"1488844\"]\n",
    "minhashes = compute_minhashes(user, n_hash)\n",
    "minhashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_bucket_matrix(signatures: dict[str, np.ndarray], n_buckets = 100, bands = 10):\n",
    "    r = len(signatures) // bands\n",
    "    buckets = np.zeros((len(signatures), bands), dtype = int)\n",
    "    i = 0\n",
    "    for _, signature in signatures.items(): #for each object\n",
    "        for j in range(bands): #for each band\n",
    "            buckets[i,j] = bucket_hash(signature[j*r:(j+1)*r], n_buckets=n_buckets)\n",
    "        i += 1\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9619/9619 [00:17<00:00, 565.10it/s]\n"
     ]
    }
   ],
   "source": [
    "n_hashes = 1000\n",
    "b = 20\n",
    "r = n_hashes // b\n",
    "n_buckets = 10000\n",
    "\n",
    "SIG = compute_signatures(users, n_hashes, with_tqdm = True)\n",
    "buckets = create_bucket_matrix(SIG, n_buckets, bands = b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidates(buckets, users, max_size = len(users)):\n",
    "    #buckets is a matrix of size (n_users, bands)\n",
    "    ids = np.array(list(users.keys()))\n",
    "    candidates = set()\n",
    "    for band in buckets.T:\n",
    "        #find collisions\n",
    "        unique = np.unique(band)\n",
    "        for bucket_value in tqdm(unique):\n",
    "            idx = np.where(bucket_value == band)[0]\n",
    "            if len(idx) < max_size:\n",
    "                new_candidates = cartesian_product_exclude_same(ids[idx], ids[idx])\n",
    "                candidates = candidates.union(new_candidates)\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_candidates(buckets, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 213,  918, 1331, 1336, 1445, 1513, 1591, 1729, 1766, 2029, 2221,\n",
       "       2290, 2395, 2491, 2532, 2622, 2626, 3197, 4340, 4381, 4620, 4960,\n",
       "       5216, 5418, 6044, 6248, 6328, 6361, 6425, 6474, 6806, 6823, 6910,\n",
       "       6986, 6996, 7183, 7479, 7513, 7544, 7627, 7711, 8133, 8265, 8290,\n",
       "       8358, 8688, 8750, 8957, 9132, 9499, 9570, 9677, 9801, 9861, 9971])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band = buckets.T[0]\n",
    "unique = np.unique(band)\n",
    "unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
